{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enjJerZM3SQP"
   },
   "source": [
    "## 네이버 영화 리뷰 데이터로 한글 텍스트 분류\n",
    "데이터 다운로드 : https://github.com/e9t/nsmc\n",
    "\n",
    "\n",
    "1.   ratings.txt - 전체 리뷰를 모아둔 데이터, 전체 20만개의 데이터로 구성\n",
    "2.   ratings_train.txt - 학습데이터, 총 15개의 데이터로 구성\n",
    "3.   ratings_test.txt - 평가 데이터, 총 5만개의 데이터로 구성\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4RtxVcfDfW9"
   },
   "source": [
    "## 데이터 불러오기 및 분석하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sppua-R22c5C"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hFiPHAhhDuu6",
    "outputId": "61e0ef4f-c83d-4149-e458-ce2d606d9106"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 크기: \n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yjlee/Desktop/영화리뷰_감정분류(한국어)_ipynb의_사본.ipynb 셀 4\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yjlee/Desktop/%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98%28%ED%95%9C%EA%B5%AD%EC%96%B4%29_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m DATA_PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yjlee/Desktop/%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98%28%ED%95%9C%EA%B5%AD%EC%96%B4%29_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m파일 크기: \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yjlee/Desktop/%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98%28%ED%95%9C%EA%B5%AD%EC%96%B4%29_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(DATA_PATH):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yjlee/Desktop/%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98%28%ED%95%9C%EA%B5%AD%EC%96%B4%29_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mtxt\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m file:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yjlee/Desktop/%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98%28%ED%95%9C%EA%B5%AD%EC%96%B4%29_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(file\u001b[39m.\u001b[39mljust(\u001b[39m30\u001b[39m)\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(\u001b[39mround\u001b[39m(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mgetsize(DATA_PATH\u001b[39m+\u001b[39m file) \u001b[39m/\u001b[39m \u001b[39m100000\u001b[39m,\u001b[39m2\u001b[39m))\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMB\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/'"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './data/'\n",
    "print('파일 크기: ')\n",
    "for file in os.listdir(DATA_PATH):\n",
    "  if 'txt' in file:\n",
    "    print(file.ljust(30)+str(round(os.path.getsize(DATA_PATH+ file) / 100000,2))+'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "A3pUTZ2cpfTE",
    "outputId": "52604d19-f70a-4f5d-df4c-10cfdd558ed8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 파일 불러오기\n",
    "train_data = pd.read_csv(DATA_PATH + 'ratings_train.txt',header = 0, delimiter = '\\t', quoting=3)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMs173USq4Cj",
    "outputId": "7ecd7804-170a-4707-9629-bf264d6c41c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터 전체 개수: 150000\n"
     ]
    }
   ],
   "source": [
    "print('학습데이터 전체 개수: {}'.format(len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VjXmdk7qrOjf",
    "outputId": "7e861eb7-3730-4cb9-fbca-fa8f959104e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    19\n",
       "1    33\n",
       "2    17\n",
       "3    29\n",
       "4    61\n",
       "Name: document, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#리뷰 전체길이 확인\n",
    "train_length = train_data['document'].astype(str).apply(len)\n",
    "train_length.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plv0dijUsp7y",
    "outputId": "0d5817e6-0619-4e4c-adc2-afdf65d19d06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리뷰 길이 최댓값: 158\n",
      "리뷰 길이 최솟값: 1\n",
      "리뷰 길이 평균값: 35.24\n",
      "리뷰 길이 표준편차: 29.58\n",
      "리뷰 길이 중간값: 27.0\n",
      "리뷰 길이 제1사분위: 16.0\n",
      "리뷰 길이 제3사분위: 42.0\n"
     ]
    }
   ],
   "source": [
    "#리뷰 통계 정보\n",
    "print('리뷰 길이 최댓값: {}'.format(np.max(train_length)))\n",
    "print('리뷰 길이 최솟값: {}'.format(np.min(train_length)))\n",
    "print('리뷰 길이 평균값: {:.2f}'.format(np.mean(train_length)))\n",
    "print('리뷰 길이 표준편차: {:.2f}'.format(np.std(train_length)))\n",
    "print('리뷰 길이 중간값: {}'.format(np.median(train_length)))\n",
    "print('리뷰 길이 제1사분위: {}'.format(np.percentile(train_length,25)))\n",
    "print('리뷰 길이 제3사분위: {}'.format(np.percentile(train_length,75)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Mxfv0SI9_8E"
   },
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "qv_GIvtt32vn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "DATA_PATH = './data/'\n",
    "train_data = pd.read_csv(DATA_PATH+'ratings_train.txt', header = 0, delimiter='\\t', quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tawPE19HBQu6",
    "outputId": "d7d6c3de-f605-4f1f-a6a7-f581f9782130"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  아 더빙.. 진짜 짜증나네요 목소리\n",
       "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
       "2                                    너무재밓었다그래서보는것을추천한다\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\n",
       "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['document'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SyQqCHUDQbm"
   },
   "source": [
    "## 텍스트 전처리\n",
    "\n",
    "\n",
    "1.   한글 아닌 문자들 제거\n",
    "2.   문장을 단어로 나누기(어간추출)\n",
    "3.   불용어 제거\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "K36nelvtB8d3"
   },
   "outputs": [],
   "source": [
    "#전처리 함수 만들기\n",
    "def preprocessing(review, okt, remove_stopwords = False, stop_words =[]):\n",
    "  #함수인자설명\n",
    "  # review: 전처리할 텍스트\n",
    "  # okt: okt객체를 반복적으로 생성하지 않고 미리 생성 후 인자로 받음\n",
    "  # remove_stopword: 불용어를 제거할지 여부 선택. 기본값 False\n",
    "  # stop_words: 불용어 사전은 사용자가 직접 입력, 기본값 빈 리스트\n",
    "\n",
    "  # 1. 한글 및 공백 제외한 문자 모두 제거\n",
    "  review_text = re.sub('[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]','',review)\n",
    "  \n",
    "  #2. okt 객체를 활용하여 형태소 단어로 나눔\n",
    "  word_review = okt.morphs(review_text,stem=True)\n",
    "\n",
    "  if remove_stopwords:\n",
    "    #3. 불용어 제거(선택)\n",
    "    word_review = [token for token in word_review if not token in stop_words]\n",
    "  return word_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LCshVOdaF8Bo",
    "outputId": "0208bd4d-2f3c-4176-e2a7-41724cbc4136"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['더빙', '진짜', '짜증나다', '목소리'],\n",
       " ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍다', '않다'],\n",
       " ['너', '무재', '밓었', '다그', '래서', '보다', '추천', '다'],\n",
       " ['교도소', '이야기', '구먼', '솔직하다', '재미', '없다', '평점', '조정']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 텍스트 전처리\n",
    "stop_words = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한']\n",
    "okt = Okt()\n",
    "clean_train_review = []\n",
    "\n",
    "for review in train_data['document']:\n",
    "  # 리뷰가 문자열인 경우만 전처리 진행\n",
    "  if type(review) == str:\n",
    "    clean_train_review.append(preprocessing(review,okt,remove_stopwords=True,stop_words= stop_words))\n",
    "  else:\n",
    "    clean_train_review.append([]) #str이 아닌 행은 빈칸으로 놔두기\n",
    "\n",
    "clean_train_review[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1VFYa3A7GoLQ",
    "outputId": "cc0f410f-5522-41f5-e6cc-5b3ff8a2a12a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(clean_train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "2ofwRTQZHVqx"
   },
   "outputs": [],
   "source": [
    "#테스트 리뷰도 동일하게 전처리\n",
    "test_data = pd.read_csv('./data/ratings_test.txt', header = 0, delimiter='\\t', quoting=3)\n",
    "\n",
    "clean_test_review = []\n",
    "for review in test_data['document']:\n",
    "  if type(review) == str:\n",
    "    clean_test_review.append(preprocessing(review, okt, remove_stopwords=True, stop_words=stop_words))\n",
    "  else:\n",
    "    clean_test_review.append([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuUMbbqQMbjc"
   },
   "source": [
    "## 리뷰를 인덱스 벡터로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_vocab.pkl','wb') as f:\n",
    "    pickle.dump(word_vocab,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_vocab.pkl','rb') as f:\n",
    "    mydict = pickle.load(f)\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WDxn2UpXM0Fk"
   },
   "outputs": [],
   "source": [
    "# 인덱스 벡터 변환 후 일정 길이 넘어가거나 모자라는 리뷰 패딩처리\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(clean_train_review)\n",
    "train_sequences = tokenizer.texts_to_sequences(clean_train_review)\n",
    "test_sequences = tokenizer.texts_to_sequences(clean_test_review)\n",
    "\n",
    "word_vocab = tokenizer.word_index #단어사전형태\n",
    "MAX_SEQUENCE_LENGTH = 8 #문장 최대 길이\n",
    "\n",
    "#학습 데이터\n",
    "train_inputs = pad_sequences(train_sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "\n",
    "#학습 데이터 라벨 벡터화\n",
    "train_labels = np.array(train_data['label'])\n",
    "\n",
    "#평가 데이터 \n",
    "test_inputs = pad_sequences(test_sequences,maxlen=MAX_SEQUENCE_LENGTH,padding='post')\n",
    "#평가 데이터 라벨 벡터화\n",
    "test_labels = np.array(test_data['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwZBUULAZDYt"
   },
   "source": [
    "## 모델링 과정에서 사용 가능하도록 전처리 데이터 넘파이 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ccKe6pHDVNnE"
   },
   "outputs": [],
   "source": [
    "DEFAULT_PATH  = './data/'\n",
    "DATA_PATH = 'CLEAN_DATA/'\n",
    "TRAIN_INPUT_DATA = 'nsmc_train_input.npy'\n",
    "TRAIN_LABEL_DATA = 'nsmc_train_label.npy'\n",
    "TEST_INPUT_DATA = 'nsmc_test_input.npy'\n",
    "TEST_LABEL_DATA = 'nsmc_test_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "data_configs={}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab) + 1\n",
    "\n",
    "#전처리한 데이터들 파일로저장\n",
    "import os\n",
    "\n",
    "if not os.path.exists(DEFAULT_PATH + DATA_PATH):\n",
    "  os.makedirs(DEFAULT_PATH+DATA_PATH)\n",
    "\n",
    "#전처리 학습데이터 넘파이로 저장\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_INPUT_DATA,'wb'),train_inputs)\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TRAIN_LABEL_DATA,'wb'),train_labels)\n",
    "#전처리 테스트데이터 넘파이로 저장\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TEST_INPUT_DATA,'wb'),test_inputs)\n",
    "np.save(open(DEFAULT_PATH+DATA_PATH+TEST_LABEL_DATA,'wb'),test_labels)\n",
    "\n",
    "#데이터 사전 json으로 저장\n",
    "json.dump(data_configs,open(DEFAULT_PATH + DATA_PATH + DATA_CONFIGS,'w'),ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idO1jxsDgG7Q"
   },
   "source": [
    "## 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "CXnd4XbLerPX"
   },
   "outputs": [],
   "source": [
    "# 학습 데이터 불러오기\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xsQblg_TglcY"
   },
   "outputs": [],
   "source": [
    "#전처리 데이터 불러오기\n",
    "DATA_PATH = './data/CLEAN_DATA/'\n",
    "DATA_OUT = './data/DATA_OUT/'\n",
    "INPUT_TRAIN_DATA = 'nsmc_train_input.npy'\n",
    "LABEL_TRAIN_DATA = 'nsmc_train_label.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "\n",
    "train_input = np.load(open(DATA_PATH + INPUT_TRAIN_DATA,'rb'))\n",
    "train_input = pad_sequences(train_input,maxlen=train_input.shape[1])\n",
    "train_label = np.load(open(DATA_PATH + LABEL_TRAIN_DATA,'rb'))\n",
    "prepro_configs = json.load(open(DATA_PATH+DATA_CONFIGS,'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VssaYYLTlTm_"
   },
   "source": [
    "## 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xeYqNfjKk9iS"
   },
   "outputs": [],
   "source": [
    "model_name= 'cnn_classifier_kr'\n",
    "BATCH_SIZE = 512\n",
    "NUM_EPOCHS = 10\n",
    "VALID_SPLIT = 0.1\n",
    "MAX_LEN = train_input.shape[1]\n",
    "\n",
    "kargs={'model_name': model_name, 'vocab_size':prepro_configs['vocab_size'],'embbeding_size':128, 'num_filters':100,'dropout_rate':0.5, 'hidden_dimension':250,'output_dimension':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CNxmES7_mODQ"
   },
   "source": [
    "## 모델 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8zbhuCAWmJTo"
   },
   "outputs": [],
   "source": [
    "class CNNClassifier(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, **kargs):\n",
    "    super(CNNClassifier, self).__init__(name=kargs['model_name'])\n",
    "    self.embedding = layers.Embedding(input_dim=kargs['vocab_size'], output_dim=kargs['embbeding_size'])\n",
    "    self.conv_list = [layers.Conv1D(filters=kargs['num_filters'], kernel_size=kernel_size, padding='valid',activation = tf.keras.activations.relu,\n",
    "                                    kernel_constraint = tf.keras.constraints.MaxNorm(max_value=3)) for kernel_size in [3,4,5]]\n",
    "    self.pooling = layers.GlobalMaxPooling1D()\n",
    "    self.dropout = layers.Dropout(kargs['dropout_rate'])\n",
    "    self.fc1 = layers.Dense(units=kargs['hidden_dimension'],\n",
    "                            activation = tf.keras.activations.relu,\n",
    "                            kernel_constraint=tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "    self.fc2 = layers.Dense(units=kargs['output_dimension'],\n",
    "                            activation=tf.keras.activations.sigmoid,\n",
    "                            kernel_constraint= tf.keras.constraints.MaxNorm(max_value=3.))\n",
    "    \n",
    "\n",
    "  def call(self,x):\n",
    "    x = self.embedding(x)\n",
    "    x = self.dropout(x)\n",
    "    x = tf.concat([self.pooling(conv(x)) for conv in self.conv_list], axis = 1)\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jyQD7kbqG-B4"
   },
   "source": [
    "## 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "YluMeQQfSk7e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import save_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11Og2GmuG8l3",
    "outputId": "202366a5-f01a-4aa4-861b-e21d5a10e708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/DATA_OUT -- Folder already exists \n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "model = CNNClassifier(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics = [tf.keras.metrics.BinaryAccuracy(name='accuracy')])\n",
    "\n",
    "#검증 정확도를 통한 EarlyStopping 기능 및 모델 저장 방식 지정\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=2)\n",
    "checkpoint_path = DATA_OUT + model_name +'\\weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "if os.path.exists(checkpoint_dir):\n",
    "  print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "  os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "  print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor = 'val_accuracy', verbose=1, save_best_only = True,\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "history = model.fit(train_input, train_label, batch_size=BATCH_SIZE, epochs = NUM_EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "# 모델 저장하기\n",
    "save_model(model,'./data/my_models/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yjlee/Desktop/영화리뷰_감정분류(한국어)_ipynb의_사본.ipynb 셀 34\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yjlee/Desktop/%EC%98%81%ED%99%94%EB%A6%AC%EB%B7%B0_%EA%B0%90%EC%A0%95%EB%B6%84%EB%A5%98%28%ED%95%9C%EA%B5%AD%EC%96%B4%29_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb#X65sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39m./data/my_models/model.h5\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('./data/my_models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8ftLdqxUPsT",
    "outputId": "799e338b-bd52-4b88-98dd-e498ce117991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tzip warning: name not matched: /content/sample_data/my_models/\n",
      "\n",
      "zip error: Nothing to do! (try: zip -r /content/sample_data/my_models.zip . -i /content/sample_data/my_models/)\n"
     ]
    }
   ],
   "source": [
    "# 모델 zip파일로 저장\n",
    "!zip -r /content/sample_data/my_models.zip /content/sample_data/my_models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "2L_glqj8U4mD",
    "outputId": "d66c8933-8616-4fcc-c113-9178e92482ce"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "download(\"download_b8b5bf72-05d8-49bb-b3c4-42a91171a63b\", \"my_models.zip\", 104930782)",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 저장된 모델 zip파일 다운로드\n",
    "from google.colab import files\n",
    "files.download('/content/sample_data/my_models.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Weo0dmDoCQEx"
   },
   "source": [
    "## 학습된 데이터로 테스트 데이터 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qaOM5M_CaiQn"
   },
   "outputs": [],
   "source": [
    "INPUT_TEST_DATA = 'nsmc_test_input.npy'\n",
    "LABEL_TEST_DATA = 'nsmc_test_label.npy'\n",
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "test_input = np.load(open(DATA_PATH+INPUT_TEST_DATA,'rb'))\n",
    "test_input = pad_sequences(test_input,maxlen=test_input.shape[1])\n",
    "test_label_data = np.load(open(DATA_PATH + LABEL_TEST_DATA, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENa9YJRWLrf8",
    "outputId": "5f8d06ab-db8b-413e-a1b7-1c8132b4bd8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3827 - accuracy: 0.8287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3827030658721924, 0.8286600708961487]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./data/DATA_OUT/cnn_classifier_kr\\weights.h5')\n",
    "model.evaluate(test_input, test_label_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osjgpM369x_V"
   },
   "source": [
    "## 문장이 긍정인지 부정인지 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8Kje-PZkQ_5",
    "outputId": "cc610976-3fd5-4ad4-ef1e-7c60ed1541a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "91.48% 확률로 긍정 리뷰입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "okt = Okt()\n",
    "tokenizer  = Tokenizer()\n",
    "\n",
    "with open('./data/word_vocab.pkl','rb') as f:\n",
    "  word_vocab = pickle.load(f)\n",
    "      \n",
    "\n",
    "DATA_CONFIGS = 'data_configs.json'\n",
    "prepro_configs = json.load(open('./data/CLEAN_DATA/'+DATA_CONFIGS,'r'))\n",
    "prepro_configs['vocab'] = word_vocab\n",
    "\n",
    "tokenizer.fit_on_texts(word_vocab)\n",
    "\n",
    "MAX_LENGTH = 8 #문장최대길이\n",
    "\n",
    "f = open('./data/review.txt', 'r')\n",
    "sentence = f.readline()\n",
    "\n",
    "\n",
    "\n",
    "#sentence = input('감성분석할 문장을 입력해 주세요.: ')\n",
    "#print(sentence)\n",
    "sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣\\\\s ]','', sentence)\n",
    "stopwords = ['은','는','이','가','하','아','것','들','의','있','되','수','보','주','등','한'] # 불용어 추가할 것이 있으면 이곳에 추가\n",
    "sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "sentence = [word for word in sentence if not word in stopwords] # 불용어 제거\n",
    "vector  = tokenizer.texts_to_sequences(sentence)\n",
    "pad_new = pad_sequences(vector, maxlen = MAX_LENGTH) # 패딩\n",
    "#print('변환된 문자 결과값: ',pad_new)\n",
    "model.load_weights('./data/DATA_OUT/cnn_classifier_kr\\weights.h5') #모델 불러오기\n",
    "predictions = model.predict(pad_new)\n",
    "predictions = float(predictions.squeeze(-1)[1])\n",
    "#print(predictions)\n",
    "if(predictions > 0.5):\n",
    "  print(\"{:.2f}% 확률로 긍정 리뷰입니다.\\n\".format(predictions * 100))\n",
    "else:\n",
    "  print(\"{:.2f}% 확률로 부정 리뷰입니다.\\n\".format((1 - predictions) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bWmFGyFwUIu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "14763c0aa030f96a438b6041b582aebbe0b24ad2b6010de84bcf7102be519e1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
